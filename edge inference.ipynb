{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# /deploy/edge_inference.py\n\"\"\"\nEdge Inference Script for Operation FractureScope\nDetects micro-defects (crack, corrosion, scratch) from multimodal images\nOptimized for resource-constrained edge devices\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nfrom PIL import Image\nimport time\n\n\nclass FractureNet(nn.Module):\n    def __init__(self, num_classes=3):\n        super(FractureNet, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),  # Lightweight layers\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d((1, 1))\n        )\n        self.classifier = nn.Linear(32, num_classes)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# === Preprocessing (resize + normalize) ===\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\n# === Load model weights ===\nmodel = FractureNet(num_classes=3)\nmodel.load_state_dict(torch.load('fracturenet.pth', map_location='cpu'))\nmodel.eval()\n\n# === Class labels ===\nclasses = ['crack', 'corrosion', 'scratch']\n\ndef edge_predict(image_path):\n    img = Image.open(image_path).convert('RGB')\n    img_tensor = transform(img).unsqueeze(0)  # Shape: (1, 3, 224, 224)\n    \n    start_time = time.time()\n    with torch.no_grad():\n        output = model(img_tensor)\n        probs = torch.nn.functional.softmax(output, dim=1)\n        pred_idx = torch.argmax(probs, dim=1).item()\n        pred_class = classes[pred_idx]\n        confidence = probs[0, pred_idx].item()\n    inference_time = (time.time() - start_time) * 1000  # ms\n    \n    return {\n        'prediction': pred_class,\n        'confidence': round(confidence, 3),\n        'inference_time_ms': round(inference_time, 2)\n    }\n\n# === Example Usage ===\nif __name__ == '__main__':\n    img_path = 'sample_edge_image.jpg'  # Replace with actual edge-captured image\n    result = edge_predict(img_path)\n    print(f\"[Edge Inference] Class: {result['prediction']} | Confidence: {result['confidence']} | Time: {result['inference_time_ms']} ms\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}